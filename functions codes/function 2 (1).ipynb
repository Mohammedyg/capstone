{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c57d663-6bc9-4755-8d56-a26b0e641648",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from statistics import NormalDist\n",
    "from scipy.stats import norm\n",
    "import scipy.special as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b77dc14-9047-4697-96b3-73503496b9cd",
   "metadata": {},
   "source": [
    "# Downloading the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fbed791-985d-47d9-87b6-ccb9f0af7da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load(r\"C:\\Users\\mo13\\OneDrive\\Documents\\ML course\\project\\IMP-PCMLAI-capstone-initial_data\\initial_data\\function_2\\initial_inputs.npy\")\n",
    "y = np.load(r\"C:\\Users\\mo13\\OneDrive\\Documents\\ML course\\project\\IMP-PCMLAI-capstone-initial_data\\initial_data\\function_2\\initial_outputs.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2410c5d6-7946-4d11-8273-57deadd9bfc6",
   "metadata": {},
   "source": [
    "Here I'm appending the inputs resulted from the acquisition function below, so everytime I get an query, I add it here to the input \"x\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bb96895-0186-4542-9fb3-2eb7d1e4dd18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.66579958, 0.12396913],\n",
       "       [0.87779099, 0.7786275 ],\n",
       "       [0.14269907, 0.34900513],\n",
       "       [0.84527543, 0.71112027],\n",
       "       [0.45464714, 0.29045518],\n",
       "       [0.57771284, 0.77197318],\n",
       "       [0.43816606, 0.68501826],\n",
       "       [0.34174959, 0.02869772],\n",
       "       [0.33864816, 0.21386725],\n",
       "       [0.70263656, 0.9265642 ],\n",
       "       [0.        , 0.424242  ],\n",
       "       [0.        , 0.363636  ],\n",
       "       [0.        , 0.        ],\n",
       "       [0.272727  , 0.999999  ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.append(X,[[0, 0.424242], [0, 0.363636], [0, 0], [0.272727, 0.999999]], axis=0)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22eb2f05-1727-45bf-8781-0955690000f8",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d16f5c-a538-4853-90bc-6525c8fc2e66",
   "metadata": {},
   "source": [
    "Here I'm appending outputs I get from the feedback, so evertime I get the output from the feedback, I add it to the output \"y\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e10d0c60-5c2d-4cae-b5f9-411d49541ebe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.53899612,  0.42058624, -0.06562362,  0.29399291,  0.21496451,\n",
       "        0.02310555,  0.24461934,  0.03874902, -0.01385762,  0.61120522,\n",
       "       -0.011816  ,  0.04148   ,  0.11562821, -0.03054567])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.append(y,[-0.011816, 0.04148, 0.115628206, -0.030545674], axis=0)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59baf3f-3c0d-4ed5-9828-6b957378ed2e",
   "metadata": {},
   "source": [
    "# Fitting in Guassian Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fffbfd8-bef3-4e39-a32c-1b24a4e08999",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpr = GaussianProcessRegressor()\n",
    "gpr.fit(X, y);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af8f0c5-4dc2-456d-ac30-be82e38a8f25",
   "metadata": {},
   "source": [
    "# Creating a grid for grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3d793df-b65e-41cb-a999-0fb0379b778d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.linspace(0, 1, 100)\n",
    "x2 = np.linspace(0, 1, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf18a21f-15df-4f9f-b091-3a66b5d10280",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_grid = []\n",
    "for i in range(len(x1)):\n",
    "    for j in range(len(x2)):\n",
    "        X_grid.append([x1[i], x2[j]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9deaf81-31ce-4fb9-8ede-9773d78507b4",
   "metadata": {},
   "source": [
    "Implementing the grid search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df239086-57b4-4575-8f00-c0a3a15fe9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_grid = np.array(X_grid)\n",
    "mean, std = gpr.predict(X_grid, return_std = True)\n",
    "\n",
    "\n",
    "#####################################################################################################\n",
    "#Below is my previous approach where I used the probability improvement method for the Acquisition Function (you can ignor it)\n",
    "#ucb = mean + 1.96 * std\n",
    "#acquisition_function = []\n",
    "#eta=0.1\n",
    "#mx = max([-0.011816, 0.04148])\n",
    "#for k in range(len(X_grid)):\n",
    " #   acquisition_function.append(1 - NormalDist(mu = mean[k], sigma = std[k]).cdf(mx + eta))\n",
    "  #  if  mean[k] > mx:\n",
    "   #     mx = mean[k]\n",
    "#acquisition_function = np.array(acquisition_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc35b1c-420d-4bfe-8631-1e1bf11b005c",
   "metadata": {},
   "source": [
    "# Applying the \"Analytic LogEI\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8715afdb-b049-492b-bc2b-dfeebb62f5d4",
   "metadata": {},
   "source": [
    "I have found this approach in \"Unexpected Improvements to Expected Improvement for Bayesian Optimization\" article (expalined in README file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbeefa3-4684-4cc9-84d8-df71fc520c6c",
   "metadata": {},
   "source": [
    "Now let's define log1mexp which is $$log( 1 - exp(x) )$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2378b462-8d7c-407b-b0c8-b374fbd3b0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log1mexp(x):\n",
    "    return np.log(1-np.exp(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983cfb32-752d-45ed-8961-91c664401b98",
   "metadata": {},
   "source": [
    "$log( 1 - exp(x) )$ is used in the acquistion function later"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac5fbe2-24ea-4b28-836f-169d775d0c66",
   "metadata": {},
   "source": [
    "Recall from README file: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26628f69-b4ae-4286-8c39-8e377989a574",
   "metadata": {},
   "source": [
    "$$c1 = log(2π) / 2$$\n",
    "$$c2 =  log(π/2) /2$$\n",
    "$$erfcx(x) = exp(x^{2})erfc(x)$$\n",
    "where erfc is the complementary error function.\n",
    "The \"Analytic LogEI\" acquistion function is: $$ LogEIy^{∗}(x) = log_h((µ(x) − y^{∗})/σ(x)) + log(σ(x))$$\n",
    "where $log_h(x)$ is calculated below (based on several conditions mentioned in README file and the article (section 4.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230822a7-378f-46ee-a5aa-b80b414ef87e",
   "metadata": {},
   "source": [
    "eta in the code below is ϵ which is chosen to be 0.1. So Let's apply that below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be083b25-dfd5-485a-8fc7-b2da9f5419c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-34.53877746, -31.65940555, -31.02711761, ...,   0.83568366,\n",
       "         0.89574325,   0.95666201])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = (mean - max(y)) / std\n",
    "c1 = np.log(2 * (22/7)) / 2\n",
    "c2 = np.log((22/7) / 2) / 2\n",
    "eta=0.1\n",
    "\n",
    "if (z > -1).any:   # the first condition for log_h\n",
    "    log_h = np.log(norm.pdf(z) + z * norm.cdf(z) + 1e-10)   # I added \"1e-10\" to avoid division by zero\n",
    "\n",
    "elif (-1/np.sqrt(eta) < z).any() and (z <= -1).any():     # the second condition for log_h\n",
    "    log_h = -z**2/(2-c1) + log1mexp(np.log(sp.erfcx(-z/np.sqrt(2)) * abs(z)) + c2)\n",
    "\n",
    "elif (z <= -1 / np.sqrt(eta)).any():    # the third condition for log_h\n",
    "    log_h = -z**2/(2-c1) + 2* np.log(abs(z))\n",
    "\n",
    "acquisition_function = log_h + np.log(std)\n",
    "acquisition_function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786cc4d7-83ed-4e53-a5a8-4d3da1c132f1",
   "metadata": {},
   "source": [
    "# Obtaining the next Query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49fc019b-d9b3-4504-850d-5e96c5cc11a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.       0.323232]\n"
     ]
    }
   ],
   "source": [
    "idx_max = np.argmax(acquisition_function)\n",
    "next_query = X_grid[idx_max]\n",
    "print(next_query.round(6))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
