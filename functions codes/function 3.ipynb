{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c57d663-6bc9-4755-8d56-a26b0e641648",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from statistics import NormalDist\n",
    "from scipy.stats import norm\n",
    "import scipy.special as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9720932-dde3-458f-8cf6-263e0c70d6c0",
   "metadata": {},
   "source": [
    "# Downloading the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fbed791-985d-47d9-87b6-ccb9f0af7da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load(r\"C:\\Users\\mo13\\OneDrive\\Documents\\ML course\\project\\IMP-PCMLAI-capstone-initial_data\\initial_data\\function_3\\initial_inputs.npy\")\n",
    "y = np.load(r\"C:\\Users\\mo13\\OneDrive\\Documents\\ML course\\project\\IMP-PCMLAI-capstone-initial_data\\initial_data\\function_3\\initial_outputs.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1549e214-10c3-42f9-b4d1-a62ab8a54ef9",
   "metadata": {},
   "source": [
    "Here I'm appending the inputs resulted from the acquisition function below, so everytime I get an query, I add it here to the input \"x\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bb96895-0186-4542-9fb3-2eb7d1e4dd18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.17152521, 0.34391687, 0.2487372 ],\n",
       "       [0.24211446, 0.64407427, 0.27243281],\n",
       "       [0.53490572, 0.39850092, 0.17338873],\n",
       "       [0.49258141, 0.61159319, 0.34017639],\n",
       "       [0.13462167, 0.21991724, 0.45820622],\n",
       "       [0.34552327, 0.94135983, 0.26936348],\n",
       "       [0.15183663, 0.43999062, 0.99088187],\n",
       "       [0.64550284, 0.39714294, 0.91977134],\n",
       "       [0.74691195, 0.28419631, 0.22629985],\n",
       "       [0.17047699, 0.6970324 , 0.14916943],\n",
       "       [0.22054934, 0.29782524, 0.34355534],\n",
       "       [0.66601366, 0.67198515, 0.2462953 ],\n",
       "       [0.04680895, 0.23136024, 0.77061759],\n",
       "       [0.60009728, 0.72513573, 0.06608864],\n",
       "       [0.96599485, 0.86111969, 0.56682913],\n",
       "       [0.373737  , 1.        , 0.        ],\n",
       "       [1.        , 0.        , 0.656566  ],\n",
       "       [0.        , 0.        , 0.949495  ],\n",
       "       [0.494949  , 0.        , 0.717172  ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.append(X,[[0.373737, 1, 0], [1, 0, 0.656566], [0, 0, 0.949495], [0.494949, 0, 0.717172]], axis=0)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e83c0d-a9c9-4dd8-b5d4-d2c8ce1bac95",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c8b079-8a0f-4cf9-a2a9-0bd01be1dc3c",
   "metadata": {},
   "source": [
    "Here I'm appending outputs I get from the feedback, so evertime I get the output from the feedback, I add it to the output \"y\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e10d0c60-5c2d-4cae-b5f9-411d49541ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.append(y,[-0.169538034, -0.1212037, -0.279407422, -0.19009924], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58eb3281-5b0b-46cb-85e2-e3aa0708bbb5",
   "metadata": {},
   "source": [
    "# Fitting in Guassian Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fffbfd8-bef3-4e39-a32c-1b24a4e08999",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpr = GaussianProcessRegressor()\n",
    "gpr.fit(X, y);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315e2851-3e70-44f4-80cc-07a16b8e34f2",
   "metadata": {},
   "source": [
    "# Creating a grid for grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3d793df-b65e-41cb-a999-0fb0379b778d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.linspace(0, 1, 100)\n",
    "x2 = np.linspace(0, 1, 100)\n",
    "x3 = np.linspace(0, 1, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf18a21f-15df-4f9f-b091-3a66b5d10280",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_grid = []\n",
    "for i in range(len(x1)):\n",
    "    for j in range(len(x2)):\n",
    "        for k in range(len(x3)):\n",
    "            X_grid.append([x1[i], x2[j], x3[k]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926595a6-c1d1-4dee-b236-c04ce16cd98c",
   "metadata": {},
   "source": [
    "Implementing the grid search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df239086-57b4-4575-8f00-c0a3a15fe9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_grid = np.array(X_grid)\n",
    "mean, std = gpr.predict(X_grid, return_std = True)\n",
    "\n",
    "#####################################################################################################\n",
    "#Below is my previous approach where I used the probability improvement method for the Acquisition Function (you can ignor it)\n",
    "#ucb = mean + 1.96 * std\n",
    "#acquisition_function = []\n",
    "#eta=0.1\n",
    "#mx = max([-0.169538034, -0.1212037])\n",
    "#for k in range(len(X_grid)):\n",
    " #   acquisition_function.append(1 - NormalDist(mu = mean[k], sigma = std[k]).cdf(mx + eta))\n",
    "  #  if  mean[k] > mx:\n",
    "   #     mx = mean[k]\n",
    "#acquisition_function = np.array(acquisition_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d13a593-cbec-4467-b25c-f61eb8ca52f5",
   "metadata": {},
   "source": [
    "# Applying the \"Analytic LogEI\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14f2884-d623-4b76-93b1-f76c684a2415",
   "metadata": {},
   "source": [
    "I have found this approach in \"Unexpected Improvements to Expected Improvement for Bayesian Optimization\" article (expalined in README file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f18a465-95d2-4219-85ee-1a0dd167ff62",
   "metadata": {},
   "source": [
    "Now let's define log1mexp which is $$log( 1 - exp(x) )$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce5acff0-e56d-45be-87ce-ce2bddfd58ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log1mexp(x):\n",
    "    return np.log(1-np.exp(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c035323-949f-4598-9c4b-81487de894bc",
   "metadata": {},
   "source": [
    "$log( 1 - exp(x) )$ is used in the acquistion function later"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1186845e-575c-4d98-b661-24c11d0b4784",
   "metadata": {},
   "source": [
    "Recall from README file: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a7e036-268b-48e2-8fa8-0abd80b403ef",
   "metadata": {},
   "source": [
    "$$c1 = log(2π) / 2$$\n",
    "$$c2 =  log(π/2) /2$$\n",
    "$$erfcx(x) = exp(x^{2})erfc(x)$$\n",
    "where erfc is the complementary error function.\n",
    "The \"Analytic LogEI\" acquistion function is: $$ LogEIy^{∗}(x) = log_h((µ(x) − y^{∗})/σ(x)) + log(σ(x))$$\n",
    "where $log_h(x)$ is calculated below (based on several conditions mentioned in README file and the article (section 4.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427ab76a-76e6-4523-a691-3dab6e56217b",
   "metadata": {},
   "source": [
    "eta in the code below is ϵ which is chosen to be 0.1. So Let's apply that below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "164a0f10-7edb-4722-9a7f-ed36b4882e44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-25.33939508, -25.36642959, -25.3936498 , ...,  -0.76405736,\n",
       "        -0.75475644,  -0.7463353 ])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = (mean - max(y)) / std\n",
    "c1 = np.log(2 * (22/7)) / 2\n",
    "c2 = np.log((22/7) / 2) / 2\n",
    "eta=0.1\n",
    "\n",
    "if (z > -1).any:    # the first condition for log_h\n",
    "    log_h = np.log(norm.pdf(z) + z * norm.cdf(z) + 1e-10)    # I added \"1e-10\" to avoid division by zero\n",
    "\n",
    "elif (-1/np.sqrt(eta) < z).any() and (z <= -1).any():    # the second condition for log_h\n",
    "    log_h = -z**2/(2-c1) + log1mexp(np.log(sp.erfcx(-z/np.sqrt(2)) * abs(z)) + c2)\n",
    "\n",
    "elif (z <= -1 / np.sqrt(eta)).any():    # the third condition for log_h\n",
    "    log_h = -z**2/(2-c1) + 2* np.log(abs(z))\n",
    "\n",
    "acquisition_function = log_h + np.log(std)\n",
    "acquisition_function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9450a6-ab18-4838-b326-8bbb4b110c25",
   "metadata": {},
   "source": [
    "# Obtaining the next Query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49fc019b-d9b3-4504-850d-5e96c5cc11a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.767677 1.       0.979798]\n"
     ]
    }
   ],
   "source": [
    "idx_max = np.argmax(acquisition_function)\n",
    "next_query = X_grid[idx_max]\n",
    "print(next_query.round(6))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
